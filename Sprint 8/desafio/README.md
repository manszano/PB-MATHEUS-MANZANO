![header-image](#)

&nbsp;  
# üé• Transforma√ß√£o de Dados no AWS Glue

Este projeto tem como objetivo realizar a transforma√ß√£o e organiza√ß√£o de dados em um Data Lake, utilizando o AWS Glue. Foram implementados dois jobs principais para leitura, transforma√ß√£o e particionamento de dados.

Para replica√ß√£o, utilize o c√≥digo Python fornecido, configurando suas credenciais e depend√™ncias no ambiente AWS Glue.

---

## üìÇ Estrutura do Projeto

O projeto foi dividido em **duas etapas principais**, conforme descrito abaixo:

### 1. **Transforma√ß√£o de Dados CSV**

Nesta etapa, foi realizada a leitura de um arquivo CSV bruto da camada Raw do Data Lake, e os dados foram transformados e salvos na camada Trusted no formato Parquet. 

#### C√≥digo Python:

```python
import sys
from pyspark.sql import SparkSession

# Configura√ß√£o da SparkSession
spark = SparkSession.builder.getOrCreate()

# Lendo argumentos
raw_path = sys.argv[1]  # Caminho da camada Raw
trusted_path = sys.argv[2]  # Caminho da camada Trusted

# Lendo os dados do CSV
df = spark.read.csv(raw_path, header=True)

# Escrevendo os dados transformados em Parquet na camada Trusted
df.write.mode("overwrite").parquet(trusted_path)
```

---

### 2. **Integra√ß√£o com API TMDB**

Nesta etapa, os dados obtidos da API TMDB foram processados, enriquecidos e particionados por data de execu√ß√£o. Os dados transformados foram salvos na camada Trusted, tamb√©m no formato Parquet.

#### C√≥digo Python:

```python
from pyspark.sql import SparkSession
from pyspark.sql.functions import current_date

# Configura√ß√£o da SparkSession
spark = SparkSession.builder.getOrCreate()

# Lendo argumentos
raw_path = sys.argv[1]  # Caminho da camada Raw (JSON)
trusted_path = sys.argv[2]  # Caminho da camada Trusted

# Lendo os dados JSON
df = spark.read.json(raw_path)

# Adicionando a coluna de parti√ß√£o pela data de execu√ß√£o
df = df.withColumn("partition_date", current_date())

# Escrevendo os dados particionados em Parquet na camada Trusted
df.write.mode("overwrite").partitionBy("partition_date").parquet(trusted_path)
```

---

## üì∏ **Evid√™ncias**

### **Scripts Executados:**  
![evidencia](#)  
_A transforma√ß√£o foi executada com sucesso e os dados foram salvos conforme os padr√µes definidos._  

---

## üéØ **Resultados**

### Caminhos ou Resultados Finais:
- **Transforma√ß√£o de CSV:** Dados armazenados no seguinte diret√≥rio:  
  `trusted/zone/csv_transform/<ano>/<m√™s>/<dia>/dados.parquet`
  
- **Integra√ß√£o com API TMDB:** Dados armazenados no seguinte diret√≥rio:  
  `trusted/zone/tmdb_api/<ano>/<m√™s>/<dia>/dados.parquet`

![footer-image](#)
